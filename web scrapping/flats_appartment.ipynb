{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JaQfb4TuqV-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "headers = {\n",
        "    'authority': 'www.99acres.com',\n",
        "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'accept-language': 'en-US,en;q=0.9',\n",
        "    'cache-control': 'no-cache',\n",
        "    'dnt': '1',\n",
        "    'pragma': 'no-cache',\n",
        "    'referer': f'https://www.99acres.com/flats-in-{City}-ffid-page',\n",
        "    'sec-ch-ua': '\"Chromium\";v=\"107\", \"Not;A=Brand\";v=\"8\"',\n",
        "    'sec-ch-ua-mobile': '?0',\n",
        "    'sec-ch-ua-platform': '\"macOS\"',\n",
        "    'sec-fetch-dest': 'document',\n",
        "    'sec-fetch-mode': 'navigate',\n",
        "    'sec-fetch-site': 'same-origin',\n",
        "    'sec-fetch-user': '?1',\n",
        "    'upgrade-insecure-requests': '1',\n",
        "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/527.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
        "}"
      ],
      "metadata": {
        "id": "LB7R7pUZu3mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "project_dir = '/content/drive/MyDrive/garvit/Case Studies/Real estate/'\n",
        "\n",
        "subdirectories = ['Data', f'Data/{City}', f'Data/{City}/Flats', f'Data/{City}/Societies', f'Data/{City}/Residential', f'Data/{City}/Independent House']\n",
        "\n",
        "for subdir in subdirectories:\n",
        "    dir_path = os.path.join(project_dir, subdir)\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "        print(f\"Created directory: {dir_path}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {dir_path}\")\n"
      ],
      "metadata": {
        "id": "Naoyz47qvF7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = int(input(\"Enter page number where you got error in last run.\\nEnter page number to start from:\"))\n",
        "end = start+10\n",
        "\n",
        "pageNumber = start\n",
        "req=0\n",
        "\n",
        "flats = pd.DataFrame()\n",
        "\n",
        "try :\n",
        "    while pageNumber < end:\n",
        "        i=1\n",
        "        url = f'https://www.99acres.com/flats-in-{City}-ffid-page-{pageNumber}'\n",
        "        page = requests.get(url, headers=headers)\n",
        "        pageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "        req+=1\n",
        "        for soup in pageSoup.select_one('div[data-label=\"SEARCH\"]').select('section[data-hydration-on-demand=\"true\"]'):\n",
        "            try:\n",
        "                property_name = soup.select_one('a.srpTuple__propertyName').text.strip()\n",
        "                # Extract link\n",
        "                link = soup.select_one('a.srpTuple__propertyName')['href']\n",
        "                society = soup.select_one('#srp_tuple_society_heading').text.strip()\n",
        "            except:\n",
        "                continue\n",
        "            # Detail Page\n",
        "            page = requests.get(link, headers=headers)\n",
        "            dpageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "            req += 1\n",
        "            try:\n",
        "                #price Range\n",
        "                price = dpageSoup.select_one('#pdPrice2').text.strip()\n",
        "            except:\n",
        "                price = ''\n",
        "\n",
        "            # Area\n",
        "            try:\n",
        "                area = soup.select_one('#srp_tuple_price_per_unit_area').text.strip()\n",
        "            except:\n",
        "                area =''\n",
        "            # Area with Type\n",
        "            try:\n",
        "                areaWithType = dpageSoup.select_one('#factArea').text.strip()\n",
        "            except:\n",
        "                areaWithType = ''\n",
        "\n",
        "\n",
        "            # Configuration\n",
        "            try:\n",
        "                bedRoom = dpageSoup.select_one('#bedRoomNum').text.strip()\n",
        "            except:\n",
        "                bedRoom = ''\n",
        "            try:\n",
        "                bathroom = dpageSoup.select_one('#bathroomNum').text.strip()\n",
        "            except:\n",
        "                bathroom = ''\n",
        "            try:\n",
        "                balcony = dpageSoup.select_one('#balconyNum').text.strip()\n",
        "            except:\n",
        "                balcony = ''\n",
        "\n",
        "            try:\n",
        "                additionalRoom = dpageSoup.select_one('#additionalRooms').text.strip()\n",
        "            except:\n",
        "                additionalRoom = ''\n",
        "\n",
        "\n",
        "            # Address\n",
        "\n",
        "            try:\n",
        "                address = dpageSoup.select_one('#address').text.strip()\n",
        "            except:\n",
        "                address = ''\n",
        "            # Floor Number\n",
        "            try:\n",
        "                floorNum = dpageSoup.select_one('#floorNumLabel').text.strip()\n",
        "            except:\n",
        "                floorNum = ''\n",
        "\n",
        "            try:\n",
        "                facing = dpageSoup.select_one('#facingLabel').text.strip()\n",
        "            except:\n",
        "                facing = ''\n",
        "\n",
        "            try:\n",
        "                agePossession = dpageSoup.select_one('#agePossessionLbl').text.strip()\n",
        "            except:\n",
        "                agePossession = ''\n",
        "\n",
        "            # Nearby Locations\n",
        "\n",
        "            try:\n",
        "                nearbyLocations = [i.text.strip() for i in dpageSoup.select_one('div.NearByLocation__tagWrap').select('span.NearByLocation__infoText')]\n",
        "            except:\n",
        "                nearbyLocations = ''\n",
        "\n",
        "            # Descriptions\n",
        "            try:\n",
        "                description = dpageSoup.select_one('#description').text.strip()\n",
        "            except:\n",
        "                description = ''\n",
        "\n",
        "            # Furnish Details\n",
        "            try:\n",
        "                furnishDetails = [i.text.strip() for i in dpageSoup.select_one('#FurnishDetails').select('li')]\n",
        "            except:\n",
        "                furnishDetails = ''\n",
        "\n",
        "            # Features\n",
        "            if furnishDetails:\n",
        "                try:\n",
        "                    features = [i.text.strip() for i in dpageSoup.select('#features')[1].select('li')]\n",
        "                except:\n",
        "                    features = ''\n",
        "            else:\n",
        "                try:\n",
        "                    features = [i.text.strip() for i in dpageSoup.select('#features')[0].select('li')]\n",
        "                except:\n",
        "                    features = ''\n",
        "\n",
        "            try:\n",
        "                rating = [i.text for i in dpageSoup.select_one('div.review__rightSide>div>ul>li>div').select('div.ratingByFeature__circleWrap')]\n",
        "            except:\n",
        "                rating = ''\n",
        "            # print(top_f)\n",
        "\n",
        "            try:\n",
        "                property_id = dpageSoup.select_one('#Prop_Id').text.strip()\n",
        "            except:\n",
        "                property_id = ''\n",
        "            property_data = {\n",
        "            'property_name': property_name,\n",
        "            'link': link,\n",
        "            'society': society,\n",
        "            'price': price,\n",
        "            'area': area,\n",
        "            'areaWithType': areaWithType,\n",
        "            'bedRoom': bedRoom,\n",
        "            'bathroom': bathroom,\n",
        "            'balcony': balcony,\n",
        "            'additionalRoom': additionalRoom,\n",
        "            'address': address,\n",
        "            'floorNum': floorNum,\n",
        "            'facing': facing,\n",
        "            'agePossession': agePossession,\n",
        "            'nearbyLocations': nearbyLocations,\n",
        "            'description': description,\n",
        "            'furnishDetails': furnishDetails,\n",
        "            'features': features,\n",
        "            'rating': rating,\n",
        "            'property_id': property_id\n",
        "        }\n",
        "\n",
        "\n",
        "            temp_df = pd.DataFrame.from_records([property_data])\n",
        "            # print(temp_df)\n",
        "            flats = pd.concat([flats, temp_df], ignore_index=True)\n",
        "            i += 1\n",
        "            if req % 4==0:\n",
        "                time.sleep(10)\n",
        "            if req % 15 == 0:\n",
        "                time.sleep(50)\n",
        "        print(f'{pageNumber} -> {i}')\n",
        "        pageNumber += 1\n",
        "\n",
        "except AttributeError as e:\n",
        "    print(e)\n",
        "    print(\"----------------\")\n",
        "    print(\"\"\"Your IP might have blocked. Delete Runitme and reconnect again with updating start page number.\\n\n",
        "            You would see in output above like 1 -> 15\\ and so 1 is page number and 15 is data items extracted.\"\"\")\n",
        "    csv_file_path = f\"/content/drive/MyDrive/DSMP/Case Studies/Real estate/Data/chandigarh/Flats/flats_{City}_data-page-{start}-{pageNumber-1}.csv\"\n",
        "\n",
        "    if os.path.isfile(csv_file_path):\n",
        "        flats.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        flats.to_csv(csv_file_path, mode='a', header=True, index=False)\n"
      ],
      "metadata": {
        "id": "VGEw0W0KvId7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_csv_files(folder_path, combined_file_path):\n",
        "    combined_data = pd.DataFrame()\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            print('file_path')\n",
        "            df = pd.read_csv(file_path)\n",
        "            combined_data = combined_data.append(df, ignore_index=True)\n",
        "            os.remove(file_path)\n",
        "    combined_data.to_csv(combined_file_path, index=False)\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/garvit/Case Studies/Real estate/flats_appartment'\n",
        "combined_file_path = '/content/drive/MyDrive/garvit/Case Studies/Real estate/flats_appartment/flats.csv'\n",
        "combine_csv_files(folder_path, combined_file_path)\n"
      ],
      "metadata": {
        "id": "KlhgriHQvKxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(combined_file_path)"
      ],
      "metadata": {
        "id": "9EnZXtP0vQRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}